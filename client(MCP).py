# response.choices[0]:  Choice(finish_reason='stop', 
# index=0, logprobs=None, 
# message=ChatCompletionMessage(content='Hello! How can I assist you today? ğŸ˜Š', 
# refusal=None, 
# role='assistant', 
# annotations=None, audio=None, function_call=None, tool_calls=None, 
# reasoning_content='Okay, the user greeted me and said, "Hello." I need to respond in a friendly and helpful manner. Let\'s start with a greeting and ask how I can assist them today. Keep it open-ended to encourage them to share their issue. Maybe something like, "Hello! How can I assist you today?" That should work.'))

import asyncio, os, json, sys, textwrap, re
from contextlib import AsyncExitStack
from dotenv import load_dotenv
from openai import OpenAI
from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client


# ---------- é¢œè‰²æ ·å¼ ----------
BOLD = "\033[1m"
BLUE = "\033[34m"
GREEN = "\033[32m"
YELLOW = "\033[33m"
RESET = "\033[0m"


load_dotenv()

SYS_PROMPT = (
    "ä½ å¯ä»¥è°ƒç”¨ä»¥ä¸‹ä¸‰ç§æ•°æ®åº“å·¥å…·ï¼š"
    "[list_tables]ã€[describe_table]ã€[query_table]ã€‚è¯·æŒ‰éœ€è°ƒç”¨ï¼Œåªæ‰§è¡Œåªè¯» SQLã€‚"
    "é€šå¸¸æ¥è¯´ï¼Œä½ å¯ä»¥å…ˆè°ƒç”¨[list_tables]å·¥å…·å°†"
    "è¯·æ³¨æ„ï¼šå¦‚æœå·¥å…·æœªè¿”å›æ•°æ®ï¼Œé‚£ä¹ˆè¯·ä¸è¦ç”Ÿæˆä½ çš„å‡è±¡å€¼ï¼Œåªéœ€è¦è¯´'æœªè·å¾—æ•°æ®'ã€‚"
)

class MCPClient():

    def __init__(self) -> None:
        self.exit_stack = AsyncExitStack()
        self.api_key = os.getenv("QWEN_API_KEY")
        self.client = OpenAI(
            api_key=self.api_key,
            base_url=os.getenv("QWEN_BASE_URL"),
        )
        self.model = os.getenv("QWEN_MODEL")
        if not self.api_key:
            raise ValueError("æ— æ³•æ­£ç¡®è·å–API keyï¼Œè¯·åœ¨.envæ–‡ä»¶ä¸­é…ç½®ã€‚")
        
        # self.client = OpenAI(api_key=self.deepseek_api_key, base_url=self.base_url)
        # self.session: Optional[ClientSession] = None

    async def connect_to_server(self, path_to_script: str):
        cmd = "python" if path_to_script.endswith(".py") else "node"
        server_params = StdioServerParameters(command=cmd, args=[path_to_script])
        self.stdio, self.write = await self.exit_stack.enter_async_context(stdio_client(server_params))
        self.session: ClientSession = await self.exit_stack.enter_async_context(ClientSession(self.stdio, self.write))
        await self.session.initialize()
        
        tools = (await self.session.list_tools()).tools
        self.tool_specs = [{
            "type":"function",
            "function":{
                "name":t.name,
                "description":t.description,
                "input_schema":t.inputSchema
            }
        } for t in tools]
        print("âœ… æˆåŠŸè¿æ¥è‡³æœåŠ¡å™¨\n")
        print("âœ… å·²æ³¨å†Œå·¥å…·:", [t["function"]["name"] for t in self.tool_specs])

    async def chat_loop(self):
        messages = [{"role": "system", "content": SYS_PROMPT}]
        print("\næ¬¢è¿ä½¿ç”¨ Qwenâ€‘MCP demoï¼Œè¾“å…¥ quit é€€å‡ºã€‚")

        while True:
            user_input = input("\n" + BOLD + "æ‚¨çš„è¾“å…¥> " + RESET).strip()
            if user_input.lower() == "quit":
                print("å†è§ï¼")
                break
            messages.append({"role": "user", "content": user_input})
            await self.query_process(messages)
    
    async def query_process(self, messages):
        """é€’å½’åœ°è°ƒç”¨æ¨¡å‹ï¼›åªè¦æœ‰ tool_callsï¼Œå°±æ‰§è¡Œå·¥å…·å¹¶ç»§ç»­å¯¹è¯"""
        is_reasoning = False
        is_answering = False
        while True:
            tool_buffers: dict[int, dict] = {}
            reasoning_buf, answer_buf = [], []

            resp = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                tools=self.tool_specs,
                stream=True,
                extra_body={
                    "enable_thinking": True,
                    # "enable_search": True,
                    # "search_options": {"forced_search": True},
                },
            )

            # ---- é€å—è¯»å–æµå¼å“åº” ----
            
            for chunk in resp:
                delta = chunk.choices[0].delta

                # A. æ€è€ƒå†…å®¹
                rc = getattr(delta, "reasoning_content", None)
                txt = getattr(delta, "content", None) or ""

                if txt.startswith("Error executing tool"):
                    # åé¦ˆç»™æ¨¡å‹ï¼Œè®©å®ƒç«‹å³é‡è¯•
                    messages.append({
                        "role":"system",
                        "content": f"å·¥å…·è°ƒç”¨å¤±è´¥ï¼Œé”™è¯¯ä¿¡æ¯ï¼š{txt}\nè¯·æ£€æŸ¥å‚æ•°æˆ–è¡¨ååé‡è¯•ã€‚"
                    })
                    # è·³å‡ºå½“å‰æµï¼Œè®©æ¨¡å‹é‡å¯ä¸€æ¬¡è°ƒç”¨
                    return await self.query_process(messages)
                
                if rc:
                    if not is_reasoning:
                        print("\n" + "=" * 20 + f"ğŸ§  æ·±åº¦æ€è€ƒ" + "=" * 20 + "\n")
                        is_reasoning = True
                    reasoning_buf.append(delta.reasoning_content)
                    print(BOLD + delta.reasoning_content + RESET, end="", flush=True)
                
                    # print("\n")
                # B. æ­£æ–‡
                else:
                    answer = getattr(delta, "content", None)
                    if answer:
                        if not is_answering:
                            print ("\n" + "=" * 20 + f"æœ€ç»ˆç­”æ¡ˆ" + "=" * 20 + "\n")
                            is_answering = True    
                        answer_buf.append(delta.content)
                        print(delta.content, end="", flush=True)

                    # C. tool_calls åˆ†ç‰‡
                    if delta.tool_calls:
                        for tc in delta.tool_calls:
                            buf = tool_buffers.setdefault(tc.index, {"id": "", "name": "", "arguments": ""})
                            if tc.id:
                                buf["id"] = tc.id
                            if tc.function.name:
                                buf["name"] = tc.function.name
                            if tc.function.arguments:
                                buf["arguments"] += tc.function.arguments

            # ---- å¦‚æœæœ¬è½®åŒ…å«å·¥å…·è°ƒç”¨ ----
            if tool_buffers:
                # æ‰“å°æ€è€ƒå†…å®¹
                print("\n" + YELLOW + "âš™ï¸  æ‰§è¡Œå·¥å…·â€¦" + RESET)
                
                tool_messages = []
                err_messages = []
                any_error = False
                for buf in tool_buffers.values():
                    # 1. æ‰§è¡Œå·¥å…·
                    name = buf["name"]
                    args = json.loads(buf["arguments"] or "{}")
                    result = await self.session.call_tool(name, args)
                    
                    records = []
                    print("\nDEBUG query_mysql raw content: ", result.content)
                    for item in result.content:
                        # æ­£ç¡®åœ°å–å‡º JSON å­—ç¬¦ä¸²
                        print("\nDEBUG text raw content: ", item.text)
                        raw_json = item.text
                        try:
                             row = json.loads(raw_json)
                        except json.JSONDecodeError:
                            continue

                        text = getattr(item, "text", "")
                        records.append(row)
                        if text.startswith("Error executing tool"):
                            any_error = True
                            err_messages.append(text)

                    if any_error:
                        err_block = "\n".join(f"- {m}" for m in err_messages)
                        print("\nDEBUG err_block: ", err_block)
                        correction_msg = {
                            "role": "system",
                            "content": (
                                "æ³¨æ„ï¼šä¸Šæ¬¡è°ƒç”¨å·¥å…·æ—¶å‡ºé”™ï¼Œé”™è¯¯ä¿¡æ¯å¦‚ä¸‹ï¼š\n"
                                f"{err_block}\n"
                                "è¯·æ ¹æ®æç¤ºé‡æ–°é€‰æ‹©å·¥å…·æˆ–ä¿®æ­£å‚æ•°åå†æ¬¡è°ƒç”¨ã€‚"
                            )
                        }
                        messages.append(correction_msg)
                        continue

                    human_readable_lines = []
                    for idx, rec in enumerate(records, 1):
                        parts = [f"{k} : {v}" for k, v in rec.items()]
                        human_readable_lines.append(f"{idx}. " + " ; ".join(parts))
                    
                    human_readable = "\n".join(human_readable_lines)

                    # 2. æ„é€  tool æ¶ˆæ¯
                    tool_messages.append({
                        "role": "tool",
                        "tool_call_id": buf["id"],
                        "content": human_readable,
                    })
                    print(GREEN + f"\nã€{name} è¿”å›ã€‘\n" + RESET + human_readable)

                # 3. æ„é€  assistant æ¶ˆæ¯ï¼ˆå¸¦ tool_calls å…ƒä¿¡æ¯ï¼‰
                assistant_msg = {
                    "role": "assistant",
                    "content": human_readable,
                    "tool_calls": [
                        {
                            "id": buf["id"],
                            "function": {"name": buf["name"], "arguments": buf["arguments"]}
                        }
                        for buf in tool_buffers.values()
                    ],
                }
                messages.extend([assistant_msg, *tool_messages])
                continue
            print()            # æ¢è¡Œ
            return

    async def cleanup (self):
        await self.exit_stack.aclose()

async def main ():
    if len(sys.argv) < 2:
        print("Usage: python client.py <path_to_server_script>")
        sys.exit(1)

    client = MCPClient()
    try:
        await client.connect_to_server(sys.argv[1])
        await client.chat_loop()

    finally:
        await client.cleanup()



if __name__ == "__main__":
    asyncio.run(main())





